import sts
from datetime import datetime
from matplotlib import pyplot
import tensorflow as ts
from math import sqrt
from numpy import concatenate
from pandas import read_csv
from pandas import DataFrame
from pandas import concat
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_squared_error
 
# load and format csv
####################################################################################################################

def parse(x):
    return datetime.strptime(x, '%Y %m')
dataset = read_csv('C:\\Users\\denve\\OneDrive\\Documents\\MLData\\DL\\5rides-basic.csv',  parse_dates = [['year','month']], index_col=0, date_parser=parse)
dataset.drop('ride-0', axis=1, inplace=True)
dataset.drop('ride-1', axis=1, inplace=True)
dataset.drop('ride-2', axis=1, inplace=True)
dataset.drop('ride-3', axis=1, inplace=True)
dataset.drop('ride-4', axis=1, inplace=True)
dataset.columns = ['Month Day', 'Week day', 'Hour', 'Minute', 'DLR Open', 'DCA Open', 'DLR Close', 'DCA Close', 'Wait Ride 0', 'Open Ride 0', 'Wait Ride 1', 'Open Ride 1', 'Wait Ride 2', 'Open Ride 2', 'Wait Ride 3', 'Open Ride 3', 'Wait Ride 4', 'Open Ride 4']
dataset.index.name = 'date'

# format dataset values for network
####################################################################################################################

values = dataset.values
# convert data to float
values = values.astype('float32')
# normalize data between 0 and 1
scaler = MinMaxScaler(feature_range=(0, 1))
values = scaler.fit_transform(values)

# specify number of features / number of time steps / time in future to predict

n_steps = 1
n_rides = 5
n_features = 8 + 2 * n_rides

# which feature to predict
f_predictor = 8

# how many steps in future to predict
n_future_steps

# frame as supervised learning (shift data)
values = sts.series_to_supervised(values, n_steps, n_future_steps ,1)


# split into train and test sets
####################################################################################################################
values = values.values

n_train_steps = 20000

train = values[:n_train_steps, :]
test = values[n_train_steps:, :]
# split into input and outputs
n_obs = n_steps * n_features
train_x, train_y = train[:, :n_obs], train[:, -n_features + f_predictor]
test_x, test_y = test[:, :n_obs], test[:, -n_features + f_predictor]
# reshape input to be 3D [samples, timesteps, features]
train_x = train_x.reshape((train_x.shape[0], n_steps, n_features))
test_x = test_x.reshape((test_x.shape[0], n_steps, n_features))
 
# design network
####################################################################################################################
model = ts.keras.models.Sequential()
model.add(ts.keras.layers.LSTM(50, input_shape=(n_steps, n_features)))
model.add(ts.keras.layers.Dense(1))
model.compile(loss='mae', optimizer='adam')

# fit network
####################################################################################################################
history = model.fit(train_x, train_y, epochs=50, batch_size=200, validation_data=(test_x, test_y), verbose=2, shuffle=False)

# plot history
####################################################################################################################
pyplot.plot(history.history['loss'], label='train')
pyplot.plot(history.history['val_loss'], label='test')
pyplot.legend()
pyplot.show()

